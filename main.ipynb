{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (1.25.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (3.2.4)\n",
      "Requirement already satisfied: spacy in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (3.6.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 6)) (4.3.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (4.33.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\felma\\appdata\\roaming\\python\\python311\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\felma\\appdata\\roaming\\python\\python311\\site-packages (from nltk->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\felma\\appdata\\roaming\\python\\python311\\site-packages (from spacy->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r requirements.txt (line 7)) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r requirements.txt (line 7)) (0.17.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r requirements.txt (line 7)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r requirements.txt (line 7)) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r requirements.txt (line 7)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r requirements.txt (line 7)) (0.3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->-r requirements.txt (line 7)) (2023.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->-r requirements.txt (line 7)) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 4)) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 4)) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 4)) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 4)) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\felma\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy->-r requirements.txt (line 4)) (8.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\felma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 4)) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prezado Sr Jose Taunai  Em atenção ao seu pe...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A pedido do Pró-Reitor de Graduação, informa...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos o contato e...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos o contato e...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Prezado Prof. Gilberto Tadeu Reis da Silva  ...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           resp_text clarity\n",
       "0    Prezado Sr Jose Taunai  Em atenção ao seu pe...      c5\n",
       "1   \"A pedido do Pró-Reitor de Graduação, informa...      c5\n",
       "2   \"Prezado (a) Sr. (a), Agradecemos o contato e...    c234\n",
       "3   \"Prezado (a) Sr. (a), Agradecemos o contato e...    c234\n",
       "4   \"Prezado Prof. Gilberto Tadeu Reis da Silva  ...    c234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('datasets/ep1_esic2023_clareza_TRAIN.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5626</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Prezado(a) Senhor(a),  Sua manifestação foi a...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>41</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                resp_text clarity\n",
       "count                                                6000    6000\n",
       "unique                                               5626       3\n",
       "top      Prezado(a) Senhor(a),  Sua manifestação foi a...      c5\n",
       "freq                                                   41    2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   resp_text  6000 non-null   object\n",
      " 1   clarity    6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Reordenar baseado no rótulo 'clarity' (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prezada Senhora, Informa-se que o DNIT é uma ...</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prezada,   Os dados se referem somente aos na...</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prezado Usuário, Inicialmente agradecemos o s...</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prezada,   Referimo-nos a sua demanda, regist...</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prezada,   Segue anexa a resposta da área com...</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           resp_text clarity\n",
       "0   Prezada Senhora, Informa-se que o DNIT é uma ...      c1\n",
       "1   Prezada,   Os dados se referem somente aos na...      c1\n",
       "2   Prezado Usuário, Inicialmente agradecemos o s...      c1\n",
       "3   Prezada,   Referimo-nos a sua demanda, regist...      c1\n",
       "4   Prezada,   Segue anexa a resposta da área com...      c1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='clarity', ascending=True, inplace=True, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remover linhas vazias ou nulas, se existirem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resp_text'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   resp_text  6000 non-null   object\n",
      " 1   clarity    6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "não tinhamos nenhuma linha vazia ou nula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mudar todas as letras para caixa baixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>prezado senhor,     em atenção a solicitação ...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resp_text clarity\n",
       "2240   prezado senhor,     em atenção a solicitação ...    c234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resp_text'] = [resp.lower() for resp in df['resp_text']]\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized = df\n",
    "df_tokenized['tokens'] = [word_tokenize(resp) for resp in df['resp_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prezada senhora, informa-se que o dnit é uma ...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, senhora, ,, informa-se, que, o, dnit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prezada,   os dados se referem somente aos na...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, os, dados, se, referem, somente, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prezado usuário, inicialmente agradecemos o s...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezado, usuário, ,, inicialmente, agradecemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prezada,   referimo-nos a sua demanda, regist...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, referimo-nos, a, sua, demanda, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prezada,   segue anexa a resposta da área com...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, segue, anexa, a, resposta, da, ár...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prezada,   segue anexa a resposta da área com...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, segue, anexa, a, resposta, da, ár...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prezada,   segue em anexo resposta da área té...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, segue, em, anexo, resposta, da, á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prezado usuário, segue anexa resposta do seto...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezado, usuário, ,, segue, anexa, resposta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prezada,   segue resposta ao seu pedido de in...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, segue, resposta, ao, seu, pedido,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prezado usuário, enviamos a resposta apresent...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezado, usuário, ,, enviamos, a, resposta, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           resp_text clarity  \\\n",
       "0   prezada senhora, informa-se que o dnit é uma ...      c1   \n",
       "1   prezada,   os dados se referem somente aos na...      c1   \n",
       "2   prezado usuário, inicialmente agradecemos o s...      c1   \n",
       "3   prezada,   referimo-nos a sua demanda, regist...      c1   \n",
       "4   prezada,   segue anexa a resposta da área com...      c1   \n",
       "5   prezada,   segue anexa a resposta da área com...      c1   \n",
       "6   prezada,   segue em anexo resposta da área té...      c1   \n",
       "7   prezado usuário, segue anexa resposta do seto...      c1   \n",
       "8   prezada,   segue resposta ao seu pedido de in...      c1   \n",
       "9   prezado usuário, enviamos a resposta apresent...      c1   \n",
       "\n",
       "                                              tokens  \n",
       "0  [prezada, senhora, ,, informa-se, que, o, dnit...  \n",
       "1  [prezada, ,, os, dados, se, referem, somente, ...  \n",
       "2  [prezado, usuário, ,, inicialmente, agradecemo...  \n",
       "3  [prezada, ,, referimo-nos, a, sua, demanda, ,,...  \n",
       "4  [prezada, ,, segue, anexa, a, resposta, da, ár...  \n",
       "5  [prezada, ,, segue, anexa, a, resposta, da, ár...  \n",
       "6  [prezada, ,, segue, em, anexo, resposta, da, á...  \n",
       "7  [prezado, usuário, ,, segue, anexa, resposta, ...  \n",
       "8  [prezada, ,, segue, resposta, ao, seu, pedido,...  \n",
       "9  [prezado, usuário, ,, enviamos, a, resposta, a...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Lemmatização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "except Exception:\n",
    "    os.system(\"python -m spacy download pt_core_news_sm\")\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/chocomenta/Desktop/git/main.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chocomenta/Desktop/git/main.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mresp_text\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chocomenta/Desktop/git/main.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     sent \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(sent)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/chocomenta/Desktop/git/main.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(sent)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chocomenta/Desktop/git/main.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     temp \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39mis_punct]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chocomenta/Desktop/git/main.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     temp \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(temp)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:264\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:285\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39mself\u001b[39m, X, is_train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/ml/tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[0;32m---> 34\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[1;32m     35\u001b[0m         X,\n\u001b[1;32m     36\u001b[0m         model\u001b[39m.\u001b[39mlayers,\n\u001b[1;32m     37\u001b[0m         unseen_classes\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mattrs[\u001b[39m\"\u001b[39m\u001b[39munseen_classes\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     38\u001b[0m         train\u001b[39m=\u001b[39mis_train,\n\u001b[1;32m     39\u001b[0m         has_upper\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mattrs[\u001b[39m\"\u001b[39m\u001b[39mhas_upper\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/ml/parser_model.pyx:250\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39mself\u001b[39m, X, is_train\u001b[39m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39mself\u001b[39m, X, is_train\u001b[39m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39mself\u001b[39m, X, is_train\u001b[39m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[39mbool\u001b[39m\n\u001b[1;32m     34\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Ragged):\n\u001b[0;32m---> 36\u001b[0m         \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n\u001b[1;32m     37\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Padded):\n\u001b[1;32m     38\u001b[0m         \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ragged_forward\u001b[39m(\n\u001b[1;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[39mbool\u001b[39m\n\u001b[1;32m     89\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[1;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m     Y, get_dX \u001b[39m=\u001b[39m layer(Xr\u001b[39m.\u001b[39mdataXd, is_train)\n\u001b[1;32m     93\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYr: Ragged) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Ragged:\n\u001b[1;32m     94\u001b[0m         \u001b[39mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[39m.\u001b[39mdataXd), dYr\u001b[39m.\u001b[39mlengths)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39mself\u001b[39m, X, is_train\u001b[39m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39mself\u001b[39m, X, is_train\u001b[39m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39mself\u001b[39m, X, is_train\u001b[39m=\u001b[39mis_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/thinc/layers/maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     50\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape2f(W, nO \u001b[39m*\u001b[39m nP, nI)\n\u001b[0;32m---> 52\u001b[0m Y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mgemm(X, W, trans2\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape1f(b, nO \u001b[39m*\u001b[39m nP)\n\u001b[1;32m     54\u001b[0m Z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape3f(Y, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nO, nP)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_lemma = df\n",
    "filtered = []\n",
    "for sent in df['resp_text']:\n",
    "    sent = str(sent)\n",
    "    doc = nlp(sent)\n",
    "    temp = [token.lemma_ for token in doc if not token.is_punct]\n",
    "    temp = \" \".join(temp)\n",
    "    filtered.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma['lemma'] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prezada senhora, informa-se que o dnit é uma ...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, senhora, ,, informa-se, que, o, dnit...</td>\n",
       "      <td>prezar senhora informar se que o dnit ser um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prezada,   os dados se referem somente aos na...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, os, dados, se, referem, somente, ...</td>\n",
       "      <td>prezar    o dado se referir somente a o nasc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prezado usuário, inicialmente agradecemos o s...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezado, usuário, ,, inicialmente, agradecemo...</td>\n",
       "      <td>prezar usuário inicialmente agradecer o seu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prezada,   referimo-nos a sua demanda, regist...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, referimo-nos, a, sua, demanda, ,,...</td>\n",
       "      <td>prezar    referimo-nos o seu demanda registr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prezada,   segue anexa a resposta da área com...</td>\n",
       "      <td>c1</td>\n",
       "      <td>[prezada, ,, segue, anexa, a, resposta, da, ár...</td>\n",
       "      <td>prezar    seguir anexo o resposta de o área ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           resp_text clarity  \\\n",
       "0   prezada senhora, informa-se que o dnit é uma ...      c1   \n",
       "1   prezada,   os dados se referem somente aos na...      c1   \n",
       "2   prezado usuário, inicialmente agradecemos o s...      c1   \n",
       "3   prezada,   referimo-nos a sua demanda, regist...      c1   \n",
       "4   prezada,   segue anexa a resposta da área com...      c1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [prezada, senhora, ,, informa-se, que, o, dnit...   \n",
       "1  [prezada, ,, os, dados, se, referem, somente, ...   \n",
       "2  [prezado, usuário, ,, inicialmente, agradecemo...   \n",
       "3  [prezada, ,, referimo-nos, a, sua, demanda, ,,...   \n",
       "4  [prezada, ,, segue, anexa, a, resposta, da, ár...   \n",
       "\n",
       "                                               lemma  \n",
       "0    prezar senhora informar se que o dnit ser um...  \n",
       "1    prezar    o dado se referir somente a o nasc...  \n",
       "2    prezar usuário inicialmente agradecer o seu ...  \n",
       "3    prezar    referimo-nos o seu demanda registr...  \n",
       "4    prezar    seguir anexo o resposta de o área ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = df_lemma\n",
    "\n",
    "X = main[['lemma']]\n",
    "y = main[['clarity']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=main['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='clarity'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test['clarity'].value_counts().plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enconding do rótulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(main['lemma'])\n",
    "\n",
    "X_train_Tfidf = Tfidf_vect.transform(X_train['lemma'])\n",
    "X_test_Tfidf = Tfidf_vect.transform(X_test['lemma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53809524 0.53333333 0.57380952 0.53333333 0.5452381  0.51190476\n",
      " 0.54047619 0.52619048 0.5547619  0.57142857]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5428571428571428"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "\n",
    "scores = cross_val_score(Naive, X_train_Tfidf, y_train, cv=10)\n",
    "\n",
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mto ruim eu acho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55952381 0.56428571 0.59761905 0.55238095 0.57619048 0.53809524\n",
      " 0.52380952 0.55714286 0.56190476 0.55714286]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5588095238095238"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "\n",
    "scores = cross_val_score(SVM, X_train_Tfidf, y_train, cv=10)\n",
    "\n",
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5722222222222222"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SVM.fit(X_train_Tfidf, y_train)\n",
    "\n",
    "y_pred = SVM.predict(X_test_Tfidf)\n",
    "\n",
    "accuracy_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "não tão mlr assim, ctz que tem algo errado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5452381  0.52380952 0.56666667 0.54047619 0.55714286 0.51190476\n",
      " 0.55238095 0.54761905 0.56904762 0.5952381 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.550952380952381"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "scores = cross_val_score(RF, X_train_Tfidf, y_train, cv=10)\n",
    "\n",
    "print(scores)\n",
    "scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meio fezes tbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5722222222222222\n"
     ]
    }
   ],
   "source": [
    "SVM.fit(X_train_Tfidf, y_train)\n",
    "result = SVM.score(X_test_Tfidf, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relação entre tamanho do texto e claridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10332829414456454"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_size = df['resp_text'].str.len()\n",
    "df['text_size'] = text_size\n",
    "df['clarity_new'] = df['clarity'].replace(['c1', 'c234', 'c5'], [0,1,2])\n",
    "df['clarity_new'] = df['clarity_new'].astype('int64')\n",
    "df['clarity_new'].corr(df['text_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "legal, n tem correlaçãokkkkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['resp_text', 'clarity']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
