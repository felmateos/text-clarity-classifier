{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 23:53:01.442609: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-11 23:53:01.685707: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-11 23:53:01.685743: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-11 23:53:01.686677: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-11 23:53:01.790222: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de GPUs disponíveis: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 23:53:05.043440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 23:53:05.066459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 23:53:05.066508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Número de GPUs disponíveis:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('datasets/BERT_Embedding_1.csv')\n",
    "df_2 = pd.read_csv('datasets/BERT_Embedding_2.csv')\n",
    "\n",
    "df = pd.concat([df_1,df_2])\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "embeddings = df.iloc[:,8:].values\n",
    "labels = df['Class']\n",
    "\n",
    "# Supondo que você tenha uma coluna 'rotulo' em seu DataFrame\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Convertendo para tensores do PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Criando datasets e dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Ajuste nesta linha\n",
    "        return out\n",
    "\n",
    "# Defina os parâmetros do modelo\n",
    "input_size = 768  # número de embeddings\n",
    "hidden_size = 64  # tamanho do estado oculto\n",
    "output_size = 3  # substitua num_classes pelo número real de classes\n",
    "\n",
    "# Crie uma instância do modelo\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/100], Perda: 1.1019\n",
      "Época [2/100], Perda: 1.1014\n",
      "Época [3/100], Perda: 1.0970\n",
      "Época [4/100], Perda: 1.0929\n",
      "Época [5/100], Perda: 1.0911\n",
      "Época [6/100], Perda: 1.0897\n",
      "Época [7/100], Perda: 1.0871\n",
      "Época [8/100], Perda: 1.0838\n",
      "Época [9/100], Perda: 1.0807\n",
      "Época [10/100], Perda: 1.0783\n",
      "Época [11/100], Perda: 1.0755\n",
      "Época [12/100], Perda: 1.0718\n",
      "Época [13/100], Perda: 1.0682\n",
      "Época [14/100], Perda: 1.0654\n",
      "Época [15/100], Perda: 1.0624\n",
      "Época [16/100], Perda: 1.0592\n",
      "Época [17/100], Perda: 1.0568\n",
      "Época [18/100], Perda: 1.0545\n",
      "Época [19/100], Perda: 1.0519\n",
      "Época [20/100], Perda: 1.0500\n",
      "Época [21/100], Perda: 1.0483\n",
      "Época [22/100], Perda: 1.0461\n",
      "Época [23/100], Perda: 1.0444\n",
      "Época [24/100], Perda: 1.0424\n",
      "Época [25/100], Perda: 1.0406\n",
      "Época [26/100], Perda: 1.0393\n",
      "Época [27/100], Perda: 1.0373\n",
      "Época [28/100], Perda: 1.0354\n",
      "Época [29/100], Perda: 1.0339\n",
      "Época [30/100], Perda: 1.0321\n",
      "Época [31/100], Perda: 1.0307\n",
      "Época [32/100], Perda: 1.0291\n",
      "Época [33/100], Perda: 1.0273\n",
      "Época [34/100], Perda: 1.0258\n",
      "Época [35/100], Perda: 1.0241\n",
      "Época [36/100], Perda: 1.0226\n",
      "Época [37/100], Perda: 1.0213\n",
      "Época [38/100], Perda: 1.0202\n",
      "Época [39/100], Perda: 1.0197\n",
      "Época [40/100], Perda: 1.0184\n",
      "Época [41/100], Perda: 1.0161\n",
      "Época [42/100], Perda: 1.0149\n",
      "Época [43/100], Perda: 1.0147\n",
      "Época [44/100], Perda: 1.0132\n",
      "Época [45/100], Perda: 1.0114\n",
      "Época [46/100], Perda: 1.0110\n",
      "Época [47/100], Perda: 1.0103\n",
      "Época [48/100], Perda: 1.0087\n",
      "Época [49/100], Perda: 1.0074\n",
      "Época [50/100], Perda: 1.0071\n",
      "Época [51/100], Perda: 1.0062\n",
      "Época [52/100], Perda: 1.0047\n",
      "Época [53/100], Perda: 1.0035\n",
      "Época [54/100], Perda: 1.0033\n",
      "Época [55/100], Perda: 1.0024\n",
      "Época [56/100], Perda: 1.0010\n",
      "Época [57/100], Perda: 0.9998\n",
      "Época [58/100], Perda: 0.9993\n",
      "Época [59/100], Perda: 0.9988\n",
      "Época [60/100], Perda: 0.9977\n",
      "Época [61/100], Perda: 0.9965\n",
      "Época [62/100], Perda: 0.9954\n",
      "Época [63/100], Perda: 0.9948\n",
      "Época [64/100], Perda: 0.9943\n",
      "Época [65/100], Perda: 0.9936\n",
      "Época [66/100], Perda: 0.9929\n",
      "Época [67/100], Perda: 0.9916\n",
      "Época [68/100], Perda: 0.9905\n",
      "Época [69/100], Perda: 0.9895\n",
      "Época [70/100], Perda: 0.9887\n",
      "Época [71/100], Perda: 0.9882\n",
      "Época [72/100], Perda: 0.9881\n",
      "Época [73/100], Perda: 0.9891\n",
      "Época [74/100], Perda: 0.9899\n",
      "Época [75/100], Perda: 0.9879\n",
      "Época [76/100], Perda: 0.9842\n",
      "Época [77/100], Perda: 0.9850\n",
      "Época [78/100], Perda: 0.9862\n",
      "Época [79/100], Perda: 0.9829\n",
      "Época [80/100], Perda: 0.9821\n",
      "Época [81/100], Perda: 0.9837\n",
      "Época [82/100], Perda: 0.9811\n",
      "Época [83/100], Perda: 0.9798\n",
      "Época [84/100], Perda: 0.9809\n",
      "Época [85/100], Perda: 0.9793\n",
      "Época [86/100], Perda: 0.9779\n",
      "Época [87/100], Perda: 0.9780\n",
      "Época [88/100], Perda: 0.9777\n",
      "Época [89/100], Perda: 0.9765\n",
      "Época [90/100], Perda: 0.9753\n",
      "Época [91/100], Perda: 0.9756\n",
      "Época [92/100], Perda: 0.9752\n",
      "Época [93/100], Perda: 0.9737\n",
      "Época [94/100], Perda: 0.9731\n",
      "Época [95/100], Perda: 0.9727\n",
      "Época [96/100], Perda: 0.9725\n",
      "Época [97/100], Perda: 0.9719\n",
      "Época [98/100], Perda: 0.9707\n",
      "Época [99/100], Perda: 0.9700\n",
      "Época [100/100], Perda: 0.9695\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Defina a função de perda e o otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Treinamento\n",
    "num_epocas = 100\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    saida = model(X_train_tensor)\n",
    "    perda = criterion(saida, y_train_tensor)\n",
    "    \n",
    "    perda.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Época [{epoca + 1}/{num_epocas}], Perda: {perda.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação no conjunto de teste\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    saida_treino = model(X_train_tensor)\n",
    "    _, predicoes_treino = torch.max(saida_treino, 1)\n",
    "    acuracia_treino = torch.sum(predicoes_treino == y_train_tensor).item() / len(y_train_tensor)\n",
    "\n",
    "    saida_teste = model(X_test_tensor)\n",
    "    _, predicoes_teste = torch.max(saida_teste, 1)\n",
    "    acuracia_teste = torch.sum(predicoes_teste == y_test_tensor).item() / len(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5310416666666666\n",
      "0.5175\n"
     ]
    }
   ],
   "source": [
    "print(acuracia_treino)\n",
    "print(acuracia_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
